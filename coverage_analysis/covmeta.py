"""
This script is used to extract specific coverage for the pdf_bake_document function
from an oss-fuzz generated coverage report HTML files. It uses a list of function
signatures and their locations (generated by cg.py)
"""

#!/usr/bin/env python3
import os
import sys
import argparse
import csv
from bs4 import BeautifulSoup
from tabulate import tabulate


def parse_args():
    p = argparse.ArgumentParser(
        description="Extract line-coverage stats for selected functions (with file & line ranges)."
    )
    p.add_argument(
        "--report-dir",
        required=True,
        help="root of coverage HTML (e.g. REPORT_*/linux/src/mupdf)",
    )
    p.add_argument(
        "--functions",
        required=True,
        help="CSV file: source_path,func_name (one per line, where func_name includes args)",
    )
    return p.parse_args()


def load_functions(fn):
    """Reads CSV with lines: source_path,func_name."""
    funcs = []
    with open(fn) as fh:
        for row in csv.reader(fh):
            if not row or not row[0].strip():
                continue
            source, func = row[0].strip(), row[1].strip()
            funcs.append((source, func))
    return funcs


def extract_stats(html_path, func_name):
    """
    Parses the HTML coverage file, finds the exact declaration line matching
    'func_name' (including args), then scans its { ... } body.
    Returns (total, covered, start_line, end_line).
    """
    soup = BeautifulSoup(open(html_path, "r", encoding="utf8"), "html.parser")
    rows = soup.find_all("tr")

    total = uncovered = 0
    found_decl = False
    in_body = False
    brace_depth = 0
    start_ln = end_ln = None

    for tr in rows:
        tds = tr.find_all("td")
        if len(tds) < 3:
            continue

        ln_txt = tds[0].get_text().strip()
        try:
            ln = int(ln_txt)
        except ValueError:
            ln = None

        code = tds[2].get_text().strip()

        if not found_decl:
            if func_name in code and code.endswith(")"):
                found_decl = True
            continue

        if not in_body:
            if code == "{":
                in_body = True
                brace_depth = 0
                start_ln = end_ln = ln
            continue

        # inside function body
        hit_pre = tds[1].find("pre")
        if hit_pre:
            total += 1
            hit = hit_pre.get_text().strip()
            if hit == "0":
                uncovered += 1

        if ln is not None:
            end_ln = ln

        if code == "{":
            brace_depth += 1
        elif code == "}":
            if brace_depth == 0:
                break
            brace_depth -= 1

    return total, (total - uncovered), start_ln, end_ln


def main():
    args = parse_args()
    funcs = load_functions(args.functions)

    grand_tot = grand_cov = 0
    results = []

    for source_path, func in funcs:
        html_file = os.path.join(args.report_dir, source_path + ".html")
        if not os.path.isfile(html_file):
            print(f"Warning: {html_file} not found; skipping {func}", file=sys.stderr)
            continue

        tot, cov, start, end = extract_stats(html_file, func)
        if tot == 0:
            print(f"Warning: no lines found for {func}", file=sys.stderr)
            continue

        results.append(
            (
                f"{start}-{end}",
                f"{source_path}",
                func.split("(")[0],
                f"{cov:4d}/{tot:<4d}",
                f"{(cov / tot * 100):5.1f}%",
            )
        )
        grand_tot += tot
        grand_cov += cov

    headers = ["Line nos.", "File", "Function", "Coverage", "Pct%"]
    print(tabulate(results, headers=headers, tablefmt="github"))

    overall = grand_cov / grand_tot * 100 if grand_tot else 0
    print("\nOverall coverage for selected functions:")
    print(f"  Total lines   = {grand_tot}")
    print(f"  Covered lines = {grand_cov}")
    print(f"  Coverage      = {overall:.1f}%\n")


if __name__ == "__main__":
    main()
